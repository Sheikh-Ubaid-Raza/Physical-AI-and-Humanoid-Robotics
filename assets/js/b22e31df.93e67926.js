"use strict";(globalThis.webpackChunkwebsite_name=globalThis.webpackChunkwebsite_name||[]).push([[4594],{4790:(n,e,i)=>{i.r(e),i.d(e,{assets:()=>l,contentTitle:()=>r,default:()=>u,frontMatter:()=>s,metadata:()=>o,toc:()=>c});const o=JSON.parse('{"id":"week-07/unity-robot-visualization","title":"Unity for Robot Visualization","description":"Learning Objectives","source":"@site/docs/week-07/unity-robot-visualization.md","sourceDirName":"week-07","slug":"/week-07/unity-robot-visualization","permalink":"/Physical-AI-and-Humanoid-Robotics/docs/week-07/unity-robot-visualization","draft":false,"unlisted":false,"editUrl":"https://github.com/Sheikh-Ubaid-Raza/Physical-AI-and-Humanoid-Robotics/edit/main/docs/week-07/unity-robot-visualization.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1,"title":"Unity for Robot Visualization"},"sidebar":"tutorialSidebar","previous":{"title":"Gazebo Environment Setup: URDF/SDF Formats, Physics Simulation","permalink":"/Physical-AI-and-Humanoid-Robotics/docs/week-06/gazebo-environment-setup"},"next":{"title":"Isaac SDK and Isaac Sim Setup","permalink":"/Physical-AI-and-Humanoid-Robotics/docs/week-08/isaac-sdk-setup"}}');var t=i(4848),a=i(8453);const s={sidebar_position:1,title:"Unity for Robot Visualization"},r="Unity for Robot Visualization",l={},c=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Theory",id:"theory",level:2},{value:"Unity Robotics Hub",id:"unity-robotics-hub",level:3},{value:"URDF Importer",id:"urdf-importer",level:3},{value:"ROS TCP Connector",id:"ros-tcp-connector",level:3},{value:"Robot Simulation vs Visualization",id:"robot-simulation-vs-visualization",level:3},{value:"Code Example 1: Unity Robot Controller Script",id:"code-example-1-unity-robot-controller-script",level:2},{value:"Code Example 2: Unity Sensor Visualization Script",id:"code-example-2-unity-sensor-visualization-script",level:2},{value:"Hands-on Exercises",id:"hands-on-exercises",level:2},{value:"Summary",id:"summary",level:2},{value:"Hardware Requirements",id:"hardware-requirements",level:2}];function d(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...n.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(e.header,{children:(0,t.jsx)(e.h1,{id:"unity-for-robot-visualization",children:"Unity for Robot Visualization"})}),"\n",(0,t.jsx)(e.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,t.jsx)(e.p,{children:"By the end of this chapter, you will be able to:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Set up Unity for robot visualization and simulation"}),"\n",(0,t.jsx)(e.li,{children:"Import and configure robot models in Unity"}),"\n",(0,t.jsx)(e.li,{children:"Create realistic environments for robot visualization"}),"\n",(0,t.jsx)(e.li,{children:"Implement sensor simulation in Unity"}),"\n",(0,t.jsx)(e.li,{children:"Connect Unity visualization to ROS 2 systems"}),"\n",(0,t.jsx)(e.li,{children:"Design user interfaces for robot monitoring and control"}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Basic understanding of Unity game engine"}),"\n",(0,t.jsx)(e.li,{children:"Knowledge of robot modeling and URDF (covered in Week 5)"}),"\n",(0,t.jsx)(e.li,{children:"Experience with ROS 2 systems (covered in Weeks 3-4)"}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"theory",children:"Theory"}),"\n",(0,t.jsx)(e.p,{children:"Unity is a powerful 3D development platform that can be used for robot visualization, simulation, and teleoperation interfaces. While Gazebo is more focused on physics simulation, Unity excels in creating visually appealing and interactive environments for robot visualization."}),"\n",(0,t.jsx)(e.h3,{id:"unity-robotics-hub",children:"Unity Robotics Hub"}),"\n",(0,t.jsx)(e.p,{children:"The Unity Robotics Hub provides tools and samples to connect Unity with ROS 2, enabling bidirectional communication between Unity and ROS 2 systems. This allows for real-time visualization of robot states and sensor data from ROS 2 systems."}),"\n",(0,t.jsx)(e.h3,{id:"urdf-importer",children:"URDF Importer"}),"\n",(0,t.jsx)(e.p,{children:"Unity provides a URDF Importer package that allows importing robot models defined in URDF format. This enables leveraging existing robot models in Unity scenes."}),"\n",(0,t.jsx)(e.h3,{id:"ros-tcp-connector",children:"ROS TCP Connector"}),"\n",(0,t.jsx)(e.p,{children:"The ROS TCP Connector package enables communication between Unity and ROS 2 systems over TCP/IP. This allows Unity to subscribe to ROS 2 topics and publish messages to ROS 2 topics."}),"\n",(0,t.jsx)(e.h3,{id:"robot-simulation-vs-visualization",children:"Robot Simulation vs Visualization"}),"\n",(0,t.jsx)(e.p,{children:"In Unity, you can focus on either visualization (showing robot state and sensor data from ROS 2) or simulation (performing physics simulation and sending data to ROS 2). For visualization, Unity typically connects to a running ROS 2 system and displays the robot's state in real-time."}),"\n",(0,t.jsx)(e.h2,{id:"code-example-1-unity-robot-controller-script",children:"Code Example 1: Unity Robot Controller Script"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-csharp",children:'// RobotController.cs\n// Purpose: Unity script to control robot visualization based on ROS 2 data\n// Setup Instructions: Attach to robot GameObject in Unity\n// Run: Unity Play Mode or Build\n\nusing UnityEngine;\nusing RosMessageTypes.Std;\nusing RosMessageTypes.Geometry;\nusing RosMessageTypes.Sensor;\nusing Unity.Robotics.ROSTCPConnector;\n\npublic class RobotController : MonoBehaviour\n{\n    [SerializeField]\n    private string robotName = "my_robot";\n\n    [SerializeField]\n    private float maxLinearVelocity = 1.0f;\n    [SerializeField]\n    private float maxAngularVelocity = 1.0f;\n\n    private ROSConnection ros;\n    private TwistMsg cmdVelMsg;\n    private OdometryMsg odomMsg;\n\n    // Subscribe to topics\n    private string cmdVelTopic;\n    private string odomTopic;\n\n    void Start()\n    {\n        // Get ROS connection\n        ros = ROSConnection.GetOrCreateInstance();\n\n        // Set up topic names\n        cmdVelTopic = "/" + robotName + "/cmd_vel";\n        odomTopic = "/" + robotName + "/odom";\n\n        // Subscribe to odometry topic\n        ros.Subscribe<OdometryMsg>(odomTopic, OdomCallback);\n\n        // Initialize command message\n        cmdVelMsg = new TwistMsg();\n        cmdVelMsg.linear = new Vector3Msg();\n        cmdVelMsg.angular = new Vector3Msg();\n    }\n\n    void OdomCallback(OdometryMsg msg)\n    {\n        // Update robot position based on odometry\n        Vector3 newPosition = new Vector3(\n            (float)msg.pose.pose.position.x,\n            (float)msg.pose.pose.position.z, // Unity Y is up, ROS Z is up\n            (float)msg.pose.pose.position.y\n        );\n\n        Quaternion newRotation = new Quaternion(\n            (float)msg.pose.pose.orientation.x,\n            (float)msg.pose.pose.orientation.z, // Unity Y is up, ROS Z is up\n            (float)msg.pose.pose.orientation.y,\n            (float)msg.pose.pose.orientation.w\n        );\n\n        transform.position = newPosition;\n        transform.rotation = newRotation;\n    }\n\n    public void SendCmdVel(float linearX, float angularZ)\n    {\n        // Clamp velocities\n        cmdVelMsg.linear.x = Mathf.Clamp(linearX, -maxLinearVelocity, maxLinearVelocity);\n        cmdVelMsg.angular.z = Mathf.Clamp(angularZ, -maxAngularVelocity, maxAngularVelocity);\n\n        // Publish command\n        ros.Publish(cmdVelTopic, cmdVelMsg);\n    }\n\n    void Update()\n    {\n        // Handle input for teleoperation\n        float linearInput = Input.GetAxis("Vertical");\n        float angularInput = Input.GetAxis("Horizontal");\n\n        if (Input.GetKey(KeyCode.Space))\n        {\n            SendCmdVel(linearInput * maxLinearVelocity, angularInput * maxAngularVelocity);\n        }\n    }\n}\n'})}),"\n",(0,t.jsx)(e.p,{children:(0,t.jsx)(e.strong,{children:"Expected Output:"})}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{children:"// In Unity Console:\nConnected to ROS bridge\nSubscribed to /my_robot/odom\nPublishing to /my_robot/cmd_vel\nRobot position updated: (2.5, 0.1, 1.8)\nRobot rotation updated: (0, 0.707, 0, 0.707)\n"})}),"\n",(0,t.jsx)(e.h2,{id:"code-example-2-unity-sensor-visualization-script",children:"Code Example 2: Unity Sensor Visualization Script"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-csharp",children:'// LaserScanVisualizer.cs\n// Purpose: Visualize LIDAR data in Unity\n// Setup Instructions: Attach to GameObject to display laser scan\n// Run: Unity Play Mode\n\nusing UnityEngine;\nusing RosMessageTypes.Sensor;\nusing Unity.Robotics.ROSTCPConnector;\n\npublic class LaserScanVisualizer : MonoBehaviour\n{\n    [SerializeField]\n    private string laserTopic = "/scan";\n    [SerializeField]\n    private GameObject laserPointPrefab; // Prefab for individual laser points\n    [SerializeField]\n    private Color laserColor = Color.red;\n    [SerializeField]\n    private float maxRange = 10.0f;\n\n    private ROSConnection ros;\n    private GameObject[] laserPoints;\n    private int maxPoints = 1080; // Typical LIDAR resolution\n\n    void Start()\n    {\n        ros = ROSConnection.GetOrCreateInstance();\n        ros.Subscribe<LaserScanMsg>(laserTopic, LaserScanCallback);\n\n        // Create laser point objects\n        laserPoints = new GameObject[maxPoints];\n        for (int i = 0; i < maxPoints; i++)\n        {\n            laserPoints[i] = Instantiate(laserPointPrefab, transform);\n            laserPoints[i].SetActive(false);\n        }\n    }\n\n    void LaserScanCallback(LaserScanMsg scan)\n    {\n        // Calculate angle increment\n        float angleIncrement = (float)scan.angle_increment;\n        float currentAngle = (float)scan.angle_min;\n\n        // Process each range measurement\n        for (int i = 0; i < scan.ranges.Length && i < maxPoints; i++)\n        {\n            float range = scan.ranges[i];\n\n            if (!float.IsNaN(range) && !float.IsInfinity(range) && range <= maxRange)\n            {\n                // Calculate position in 2D space\n                float x = range * Mathf.Cos(currentAngle);\n                float y = range * Mathf.Sin(currentAngle);\n\n                // Position the laser point\n                laserPoints[i].transform.localPosition = new Vector3(x, 0.1f, y); // Y is slightly above ground\n                laserPoints[i].GetComponent<Renderer>().material.color = laserColor;\n                laserPoints[i].SetActive(true);\n            }\n            else\n            {\n                laserPoints[i].SetActive(false);\n            }\n\n            currentAngle += angleIncrement;\n        }\n\n        // Deactivate remaining points\n        for (int i = scan.ranges.Length; i < maxPoints; i++)\n        {\n            laserPoints[i].SetActive(false);\n        }\n    }\n}\n'})}),"\n",(0,t.jsx)(e.p,{children:(0,t.jsx)(e.strong,{children:"Expected Output:"})}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{children:"// Laser scan visualization shows:\n// - Points representing obstacles in the environment\n// - Real-time updating as robot moves\n// - Proper scaling and coloring of laser points\n// - Clean visualization without artifacts\n"})}),"\n",(0,t.jsx)(e.h2,{id:"hands-on-exercises",children:"Hands-on Exercises"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsx)(e.li,{children:"Create a Unity scene with a robot model imported from URDF and implement basic movement controls"}),"\n",(0,t.jsx)(e.li,{children:"Implement a camera system in Unity that follows the robot and provides multiple viewpoints"}),"\n",(0,t.jsx)(e.li,{children:"Design a user interface in Unity that displays robot sensor data and allows teleoperation"}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"summary",children:"Summary"}),"\n",(0,t.jsx)(e.p,{children:"Unity provides powerful visualization capabilities for robotics applications, complementing traditional simulation tools like Gazebo. The ability to create visually appealing and interactive environments makes Unity ideal for robot teleoperation interfaces, training applications, and presentation of robot capabilities. Integration with ROS 2 enables real-time visualization of robot systems."}),"\n",(0,t.jsx)(e.h2,{id:"hardware-requirements",children:"Hardware Requirements"}),"\n",(0,t.jsx)(e.p,{children:"This chapter can be completed using simulation environments. For physical implementation, the following hardware is recommended:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Computer with Unity Hub and Unity Editor (2021.3 LTS or newer)"}),"\n",(0,t.jsx)(e.li,{children:"Unity Robotics packages installed via Package Manager"}),"\n",(0,t.jsx)(e.li,{children:"Robot hardware for connecting to ROS 2 system (optional for basic exercises)"}),"\n",(0,t.jsx)(e.li,{children:"VR headset for immersive visualization (optional)"}),"\n"]})]})}function u(n={}){const{wrapper:e}={...(0,a.R)(),...n.components};return e?(0,t.jsx)(e,{...n,children:(0,t.jsx)(d,{...n})}):d(n)}},8453:(n,e,i)=>{i.d(e,{R:()=>s,x:()=>r});var o=i(6540);const t={},a=o.createContext(t);function s(n){const e=o.useContext(a);return o.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function r(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(t):n.components||t:s(n.components),o.createElement(a.Provider,{value:e},n.children)}}}]);